I designed the C++/pybind11 side of a resource management system. The
goal is to simplify the code for holding resources relative to the Cython
solution. Can we perform object tracking in C++? Can we separate the
resource-management code from the other code in the CUDA core modules?
Can we reduce the reliance on Cython with the aim of increasing orthogonality
and simplying the implementation?

As a demonstration, I created holders for Stream, MemPool, and Deviceptr. I
updated the CUDA core Cython code in branch pybind11_resource_holders to use
the Stream and MemPool handles. All of the tests pass. I looked into updating
the Buffer code to use Deviceptr, but it was more complex so I backed off. If
we move forward with this plan, then it should be possible.

The scheme I implemented is well documented in cuda_core_holders_demo.cpp. It
is pretty clean, involving Box types, Holder types, and Python objects. I ran
into a new bug in the driver related to 5570902. Repeated calls to
cuMemPoolImportFromShareableHandle return the same object pointer, and the
first call to destroy the pool invalidates it. I'm not sure how it happens, but
the existing code seems to work. Perhaps exceptions are being supressed somehow
in Python, but I'm pretty sure memory pools are being double-freed.

I was able to fix it in the C++ code by adding a cache, so that repeated
imports of the same memory pool are reduced to a single handle. Come to think
of it, I'm really not sure how the current code works, because there is a cache
in Python that constructs memory pools first and checks the cache second. It
would seem that that process should invalidate the pools early.

To get the tests running, I create a link in the cuda/core/tests/ directory to
the cuda_core_holders_demo.so in this directory. The code in branch
pybind11_resource_holders imports this module and builds off of the holders
there.

Should we continue, the remaining work needed is to get the Buffers working. A
definite problem comes with the Dummy* memory resources. My scheme requires a
memory pool holder as the owner in the Deviceptr box, but what if the owner is
a Python class? I think the only deallocation functions are cudaMemFree and
cudaMemFreeAsync, so the scheme should work. It might require some rework of
those dummy classes, though. Ideally, we should be able to "capture" a device
pointer, associate it with a stream, and call the correct freeing function at
the right moment.

